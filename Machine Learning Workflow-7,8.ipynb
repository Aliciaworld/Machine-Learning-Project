{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Machine Learning Workflow-7:\n",
    "\n",
    "The general machine learning projects will follow the following pipeline. However, the detailed implementation can vary. For example, oftentimes we will iterate some procedures, such as feature engineering and selection etc.\n",
    "1. Data cleaning and formatting\n",
    "2. Exploratory Data Analysis(EDA)\n",
    "3. Feature engineering and selection\n",
    "4. Split dataset and compare different models on a performance metric\n",
    "5. Perform hyperparameter tuning on the best model \n",
    "6. Evaluate the model\n",
    "7. Interpret the model results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interpret the model\n",
    "### 7.1 Feature Importances\n",
    "Exact the feature importances into a dataframe\n",
    "- feature_results = pd.DataFrame({'feature':list(train_feature.columns},'importance': final_model.feature_importances_)\n",
    "\n",
    "\n",
    "- feature_results = feature_results.sort_values('importance', ascending = False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graph the feature importances to compare visually\n",
    "- figfize(16,10)\n",
    "\n",
    "plot the 10 most important features in a horizontal bar chart\n",
    "- feature_results.loc[:9,:].plot(x='feature', y='importance', edgecolor = 'k',kind = 'barh')\n",
    "\n",
    "\n",
    "- plt.xlabel('??',size=20)\n",
    "\n",
    "\n",
    "- plt.ylabel('')\n",
    "\n",
    "\n",
    "- plt.title('??',size = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 use Feature Importances for feature selection\n",
    "Since not every feature is important for finding the target, we can try using only the top most important features in the model to see if the performance is improved. Then we can limit to these features and re-evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the names of the most important features\n",
    "- most_important_features = feature_results['feature'][:10]\n",
    "\n",
    "\n",
    "find the index that corresponds to each feature name\n",
    "- indices = [list(train_features.columns).index(x) for x in most_important_features]]\n",
    "\n",
    "\n",
    "keep only the most important features\n",
    "- x_reduced = x_train[:, indices]\n",
    "- x_test_reduced= x_test[:, indices]\n",
    "\n",
    "\n",
    "try different models using the feature reduced x_train, for example, linearregresion\n",
    "- lr = LinearRegression()\n",
    "\n",
    "\n",
    "fit on the full set of features\n",
    "- lr.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "fit on the reduced set of features\n",
    "- lr.fit(x_reduced, y_train)\n",
    "- lr_reduced_pred = lr.predict(x_test_reduced)\n",
    "\n",
    "\n",
    "we can also try the reduced feature on gradient boosted regressor\n",
    "- model_reduced = GradientBoostingRegressor(loss='lad', max_depth = 5, max_features=None, min_samples_leaf = 6,min_samples_split = 6,n_estimators=800,random_state = 42)\n",
    "- model_reduced.ft(x_reduced, y_train)\n",
    "- model_reduced_pred = model_reduced.predict(x_test_reduced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Examining a Single Decision Tree\n",
    "For tree-based ensemble, we can look at any individual estimator. Although the final model is composed of many decision trees, and looking at a single one is not indicative of the entire model, it still allows us to see the general idea of how a decision tree works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract a single tree\n",
    "- single_tree = model_reduced.estimators_[100][0]\n",
    "\n",
    "save the tree as a .dot file which can be converted to a png using command line instructions\n",
    "- tree.export_graphviz(single_tree, out_file = 'images/tree.dot', rounded =True, feature_names = most_important_features, filled = True, max_depth =3)\n",
    "\n",
    "- single_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we cann't examine every tree, looking at a single one does give us some idea how the model makes predictions. Decision tree based ensembles simply take the idea of a single decision tree and combine the predictions of many individuals in order to create a model with less variance than a single estimator. Ensembles of trees tend to be very accurate, and also are intuitive to explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
